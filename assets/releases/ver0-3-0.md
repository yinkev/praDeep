# üöÄ praDeep v0.3.0 Release Notes

**Release Date:** January 6, 2026

We're excited to announce praDeep v0.3.0! This release focuses on **developer experience improvements**, **CI/CD automation**, and **simplified local deployment**.

## ‚ú® Highlights

### üèóÔ∏è Unified PromptManager Architecture

A major refactor consolidates all prompt loading across 10+ agent modules into a centralized `PromptManager` singleton:

- **Global caching** with module-level invalidation for improved performance
- **Language fallback chain** (`zh ‚Üí en`, `en ‚Üí zh`) for seamless i18n support
- **ISO 639-1 compliance** ‚Äî all `cn/` prompt directories renamed to `zh/`
- Simplified agent code by removing redundant `_load_prompts` methods and class-level caches

### ü§ñ GitHub Actions & CI/CD

Introducing automated workflows for better code quality and easier deployment:

| Workflow | Description |
|:---|:---|
| `dependabot.yml` | Automatic dependency updates (pip, npm, GitHub Actions, Docker) |
| `tests.yml` | Automated testing on push/PR |
| `docker-publish.yml` | Auto-publish Docker images to GHCR |

### üê≥ Pre-built Docker Images

Deploy in ~30 seconds using our pre-built image from GitHub Container Registry:

docker run -d --name deeptutor \
  -p 8001:8001 -p 3782:3782 \
  --env-file .env \
  -v $(pwd)/data:/app/data \
  ghcr.io/hkuds/deeptutor:latest### üè† Local-First LLM Configuration

Simplified settings page now focuses exclusively on **local LLM providers**:

- ‚úÖ **Ollama** (default)
- ‚úÖ **LM Studio**
- ‚ùå Removed cloud providers (OpenAI, Gemini, Azure, etc.)

This aligns with praDeep's vision for privacy-first, self-hosted AI tutoring.

## üì¶ What's Changed

### Core Infrastructure

- Added `src/core/prompt_manager.py` with singleton `PromptManager`
- Export `get_prompt_manager()` from `src/core/__init__.py`
- Added `/api/v1/config/agents` endpoint for data-driven frontend configuration

### Agent Modules Migrated (10 files)

- `research/agents/base_agent.py`
- `solve/base_agent.py`
- `guide/agents/base_guide_agent.py`
- `question/agents/generation_agent.py`
- `question/agents/validation_agent.py`
- `question/validation_workflow.py`
- `ideagen/idea_generation_workflow.py`
- `ideagen/material_organizer_agent.py`
- `co_writer/edit_agent.py`
- `co_writer/narrator_agent.py`

### Removed Legacy Code

- Deleted `src/agents/solve/utils/prompt_loader.py`
- Removed `use_prompt_loader` parameter from `BaseAgent`
- Cleaned up `_PROMPT_CACHE` class-level caches across all modules
- Removed `PromptLoader` exports from `solve/__init__.py`

## ‚¨ÜÔ∏èUpgrade

git pull origin main
docker pull ghcr.io/hkuds/deeptutor:latest*Closes #33*
## What's Changed
* fix(UI): unrendered markdown in ActivityDetail card by @tusharkhatriofficial in https://github.com/HKUDS/praDeep/pull/26
* chore: transtale readme to ru by @oshliaer in https://github.com/HKUDS/praDeep/pull/27
* fix: improve reload_excludes configuration for uvicorn server and added support for newer models (openai) by @LouisACR in https://github.com/HKUDS/praDeep/pull/28
* feat: Dynamic LLM Provider Support (Local & Cloud) by @ahmedjawedaj in https://github.com/HKUDS/praDeep/pull/34

## ü§ùNew Contributors
* @oshliaer made their first contribution in https://github.com/HKUDS/praDeep/pull/27
* @LouisACR made their first contribution in https://github.com/HKUDS/praDeep/pull/28
* @ahmedjawedaj made their first contribution in https://github.com/HKUDS/praDeep/pull/34
